import mlflow
import os
import tempfile
import zipfile
import shutil
import pickle
import requests
from typing import Any, Dict
from contextlib import contextmanager
import logging
import mimetypes
logger = logging.getLogger("FastAPITracker")
logger.setLevel(logging.INFO)  # Ou INFO si tu veux moins de verbositÃ©

if not logger.handlers:  # Pour Ã©viter d'ajouter plusieurs handlers
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)


class FastAPITracker:
    def __init__(self, tracking_uri: str):
        self.tracking_uri = tracking_uri.rstrip("/")
        self.run_id = None
        self.experiment_name = None
        logger.info(f"ğŸ”— [Init] Tracking URI dÃ©finie sur : {self.tracking_uri}")

    def set_experiment(self, experiment_name: str):
        self.experiment_name = experiment_name
        logger.info(f"ğŸ§ª [ExpÃ©rience] Nom de l'expÃ©rience dÃ©fini : {self.experiment_name}")

    @contextmanager
    def start_run(self, run_name: str = None):
        payload = {"experiment_name": self.experiment_name}
        if run_name:
            payload["run_name"] = run_name
        logger.info(f"ğŸš€ [Run] DÃ©marrage dâ€™un run : {run_name or '(sans nom)'}")
        response = requests.post(f"{self.tracking_uri}/create-run", json=payload)
        response.raise_for_status()
        self.run_id = response.json()["run_id"]
        logger.info(f"âœ… [Run] Run lancÃ© avec lâ€™ID : {self.run_id}")
        try:
            yield self
        finally:
            logger.info(f"ğŸ›‘ [Run] Fin du run avec lâ€™ID : {self.run_id}")
            self.run_id = None

    def log_params(self, params: Dict[str, Any]):
        logger.info(f"ğŸ› ï¸ [ParamÃ¨tres] Enregistrement de {len(params)} paramÃ¨tres : {params}")
        payload = {"run_id": self.run_id, "params": params}
        response = requests.post(f"{self.tracking_uri}/log-params", json=payload)
        response.raise_for_status()
        logger.info(f"âœ… [ParamÃ¨tres] ParamÃ¨tres enregistrÃ©s avec succÃ¨s.")

    def log_metrics(self, metrics: Dict[str, float]):
        logger.info(f"ğŸ“Š [MÃ©triques] Enregistrement de {len(metrics)} mÃ©triques : {metrics}")
        payload = {"run_id": self.run_id, "metrics": metrics}
        response = requests.post(f"{self.tracking_uri}/log-metrics", json=payload)
        response.raise_for_status()
        logger.info(f"âœ… [MÃ©triques] MÃ©triques enregistrÃ©es avec succÃ¨s.")

    def log_artifact(self, file_path: str, artifact_path: str = ""):
      logger.info(f"ğŸ“Š [Artefact] Sauvegarde de {file_path} dans le dossier {artifact_path}")
      mimetype = mimetypes.guess_type(file_path)[0] or "application/octet-stream"
      with open(file_path, "rb") as f:
          files = {
              "artifact_file": (os.path.basename(file_path), f, mimetype)
          }
          data = {
              "run_id": self.run_id,
              "artifact_path": artifact_path  # ce sera un dossier
          }
          response = requests.post(f"{self.tracking_uri}/log-artifact", data=data, files=files)
          response.raise_for_status()


    def log_model(self, model, artifact_path: str, model_type: str = "sklearn", input_example=None):
        logger.info(f"ğŸ§  [ModÃ¨le] Sauvegarde du modÃ¨le ({model_type}) en cours...")
        if mlflow.active_run() is not None:
            mlflow.end_run()

        with tempfile.TemporaryDirectory() as tmpdir:
            with mlflow.start_run() as local_run:
                model_dir = os.path.join(tmpdir, "model_artifact")
                logger.info(f"ğŸ“ [Temp] Dossier temporaire crÃ©Ã© : {model_dir}")

                if model_type == "sklearn":
                    mlflow.sklearn.save_model(sk_model=model, path=model_dir, input_example=input_example)
                elif model_type == "keras":
                    mlflow.keras.save_model(model, path=model_dir, input_example=input_example)
                elif model_type == "pyfunc":
                    mlflow.pyfunc.save_model(path=model_dir, python_model=model, input_example=input_example)
                else:
                    raise ValueError(f"ğŸš« [Erreur] Type de modÃ¨le non supportÃ© : {model_type}")

                logger.info(f"âœ… [ModÃ¨le] ModÃ¨le sauvegardÃ© localement.")

            zip_path = os.path.join(tmpdir, "model.zip")
            with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zipf:
                for root, _, files in os.walk(model_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        arcname = os.path.relpath(file_path, model_dir)
                        zipf.write(file_path, arcname)

            logger.info(f"ğŸ—œï¸ [ZIP] ModÃ¨le compressÃ© dans : {zip_path}")
            logger.debug(f"ğŸ” [DEBUG] Existe ? {os.path.exists(zip_path)}")
            logger.debug(f"ğŸ“¦ [DEBUG] Taille ZIP : {os.path.getsize(zip_path)} octets")
            logger.debug(f"âœ… [DEBUG] ZIP valide ? {zipfile.is_zipfile(zip_path)}")

            with open(zip_path, "rb") as f:
                files = {"zipped_model": (f"{artifact_path}.zip", f, "application/zip")}
                data = {
                    "run_id": self.run_id,
                    "artifact_path": artifact_path,
                    "model_type": model_type
                }
                logger.info(f"ğŸ“¤ [Upload] Envoi du modÃ¨le Ã  lâ€™API pour enregistrement...")
                response = requests.post(f"{self.tracking_uri}/log-model", data=data, files=files)
                response.raise_for_status()
                logger.info(f"ğŸ‰ [SuccÃ¨s] ModÃ¨le envoyÃ© et enregistrÃ© avec succÃ¨s.")
